"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.BulkWriter = exports.BulkWriterError = exports.DEFAULT_JITTER_FACTOR = exports.DEFAULT_MAXIMUM_OPS_PER_SECOND_LIMIT = exports.DEFAULT_INITIAL_OPS_PER_SECOND_LIMIT = exports.RETRY_MAX_BATCH_SIZE = void 0;
const assert = require("assert");
const backoff_1 = require("./backoff");
const rate_limiter_1 = require("./rate-limiter");
const timestamp_1 = require("./timestamp");
const util_1 = require("./util");
const write_batch_1 = require("./write-batch");
const validate_1 = require("./validate");
const logger_1 = require("./logger");
const trace_util_1 = require("./telemetry/trace-util");

const MAX_BATCH_SIZE = 20;

exports.RETRY_MAX_BATCH_SIZE = 10;

exports.DEFAULT_INITIAL_OPS_PER_SECOND_LIMIT = 500;

exports.DEFAULT_MAXIMUM_OPS_PER_SECOND_LIMIT = 10000;

exports.DEFAULT_JITTER_FACTOR = 0.3;

const RATE_LIMITER_MULTIPLIER = 1.5;

const RATE_LIMITER_MULTIPLIER_MILLIS = 5 * 60 * 1000;

const DEFAULT_MAXIMUM_PENDING_OPERATIONS_COUNT = 500;

class BulkWriterOperation {
    
    constructor(ref, type, sendFn, errorFn, successFn) {
        this.ref = ref;
        this.type = type;
        this.sendFn = sendFn;
        this.errorFn = errorFn;
        this.successFn = successFn;
        this.deferred = new util_1.Deferred();
        this.failedAttempts = 0;
        this._backoffDuration = 0;
        
        this._flushed = false;
    }
    get promise() {
        return this.deferred.promise;
    }
    get backoffDuration() {
        return this._backoffDuration;
    }
    markFlushed() {
        this._flushed = true;
    }
    get flushed() {
        return this._flushed;
    }
    onError(error) {
        ++this.failedAttempts;
        try {
            const bulkWriterError = new BulkWriterError(error.code, error.message, this.ref, this.type, this.failedAttempts);
            const shouldRetry = this.errorFn(bulkWriterError);
            (0, logger_1.logger)('BulkWriter.errorFn', null, 'Ran error callback on error code:', error.code, ', shouldRetry:', shouldRetry, ' for document:', this.ref.path);
            if (shouldRetry) {
                this.lastStatus = error.code;
                this.updateBackoffDuration();
                this.sendFn(this);
            }
            else {
                this.deferred.reject(bulkWriterError);
            }
        }
        catch (userCallbackError) {
            this.deferred.reject(userCallbackError);
        }
    }
    updateBackoffDuration() {
        if (this.lastStatus === 8 ) {
            this._backoffDuration = backoff_1.DEFAULT_BACKOFF_MAX_DELAY_MS;
        }
        else if (this._backoffDuration === 0) {
            this._backoffDuration = backoff_1.DEFAULT_BACKOFF_INITIAL_DELAY_MS;
        }
        else {
            this._backoffDuration *= backoff_1.DEFAULT_BACKOFF_FACTOR;
        }
    }
    onSuccess(result) {
        try {
            this.successFn(this.ref, result);
            this.deferred.resolve(result);
        }
        catch (userCallbackError) {
            this.deferred.reject(userCallbackError);
        }
    }
}

class BulkCommitBatch extends write_batch_1.WriteBatch {
    constructor(firestore, maxBatchSize) {
        super(firestore);

        this.docPaths = new Set();


        this.pendingOps = [];
        this._maxBatchSize = maxBatchSize;
    }
    get maxBatchSize() {
        return this._maxBatchSize;
    }
    setMaxBatchSize(size) {
        assert(this.pendingOps.length <= size, 'New batch size cannot be less than the number of enqueued writes');
        this._maxBatchSize = size;
    }
    has(documentRef) {
        return this.docPaths.has(documentRef.path);
    }
    async bulkCommit(options = {}) {
        return this._firestore._traceUtil.startActiveSpan(trace_util_1.SPAN_NAME_BULK_WRITER_COMMIT, async () => {
            var _a;
            const tag = (_a = options === null || options === void 0 ? void 0 : options.requestTag) !== null && _a !== void 0 ? _a : (0, util_1.requestTag)();

            const stack = Error().stack;
            let response;
            try {
                (0, logger_1.logger)('BulkCommitBatch.bulkCommit', tag, `Sending next batch with ${this._opCount} writes`);
                const retryCodes = (0, util_1.getRetryCodes)('batchWrite');
                response = await this._commit({ retryCodes, methodName: 'batchWrite', requestTag: tag });
            }
            catch (err) {

                const ops = Array.from({ length: this.pendingOps.length });
                response = {
                    writeResults: ops.map(() => {
                        return {};
                    }),
                    status: ops.map(() => err),
                };
            }
            for (let i = 0; i < (response.writeResults || []).length; ++i) {



                const DELETE_TIMESTAMP_SENTINEL = timestamp_1.Timestamp.fromMillis(0);
                const status = (response.status || [])[i];
                if (status.code === 0 ) {
                    const updateTime = timestamp_1.Timestamp.fromProto(response.writeResults[i].updateTime || DELETE_TIMESTAMP_SENTINEL);
                    this.pendingOps[i].onSuccess(new write_batch_1.WriteResult(updateTime));
                }
                else {
                    const error = new (require('google-gax/build/src/fallback').GoogleError)(status.message || undefined);
                    error.code = status.code;
                    this.pendingOps[i].onError((0, util_1.wrapError)(error, stack));
                }
            }
        }, {
            [trace_util_1.ATTRIBUTE_KEY_DOC_COUNT]: this._opCount,
        });
    }
    
    processLastOperation(op) {
        assert(!this.docPaths.has(op.ref.path), 'Batch should not contain writes to the same document');
        this.docPaths.add(op.ref.path);
        this.pendingOps.push(op);
    }
}

class BufferedOperation {
    constructor(operation, sendFn) {
        this.operation = operation;
        this.sendFn = sendFn;
    }
}

class BulkWriterError extends Error {
    
    constructor(
    
    code, 
    
    message, 
    

    documentRef, 
    
    operationType, 
    
    failedAttempts) {
        super(message);
        this.code = code;
        this.message = message;
        this.documentRef = documentRef;
        this.operationType = operationType;
        this.failedAttempts = failedAttempts;
    }
}
exports.BulkWriterError = BulkWriterError;

class BulkWriter {

    
    _getBufferedOperationsCount() {
        return this._bufferedOperations.length;
    }

    
    _setMaxBatchSize(size) {
        assert(this._bulkCommitBatch.pendingOps.length === 0, 'BulkCommitBatch should be empty');
        this._maxBatchSize = size;
        this._bulkCommitBatch = new BulkCommitBatch(this.firestore, size);
    }

    
    _setMaxPendingOpCount(newMax) {
        this._maxPendingOpCount = newMax;
    }
    
    constructor(firestore, options) {
        var _a, _b;
        this.firestore = firestore;
        
        this._maxBatchSize = MAX_BATCH_SIZE;
        
        this._bulkCommitBatch = new BulkCommitBatch(this.firestore, this._maxBatchSize);
        
        this._lastOp = Promise.resolve();
        
        this._pendingOpsCount = 0;
        
        this._bufferedOperations = [];
        
        this._errorHandlerSet = false;
        
        this._maxPendingOpCount = DEFAULT_MAXIMUM_PENDING_OPERATIONS_COUNT;
        
        this._successFn = () => { };
        
        this._errorFn = error => {
            const isRetryableDeleteError = error.operationType === 'delete' &&
                error.code === 13 ;
            const retryCodes = (0, util_1.getRetryCodes)('batchWrite');
            return ((retryCodes.includes(error.code) || isRetryableDeleteError) &&
                error.failedAttempts < backoff_1.MAX_RETRY_ATTEMPTS);
        };
        this.firestore._incrementBulkWritersCount();
        validateBulkWriterOptions(options);
        if ((options === null || options === void 0 ? void 0 : options.throttling) === false) {
            this._rateLimiter = new rate_limiter_1.RateLimiter(Number.POSITIVE_INFINITY, Number.POSITIVE_INFINITY, Number.POSITIVE_INFINITY, Number.POSITIVE_INFINITY);
        }
        else {
            let startingRate = exports.DEFAULT_INITIAL_OPS_PER_SECOND_LIMIT;
            let maxRate = exports.DEFAULT_MAXIMUM_OPS_PER_SECOND_LIMIT;
            if (typeof (options === null || options === void 0 ? void 0 : options.throttling) !== 'boolean') {
                if (((_a = options === null || options === void 0 ? void 0 : options.throttling) === null || _a === void 0 ? void 0 : _a.maxOpsPerSecond) !== undefined) {
                    maxRate = options.throttling.maxOpsPerSecond;
                }
                if (((_b = options === null || options === void 0 ? void 0 : options.throttling) === null || _b === void 0 ? void 0 : _b.initialOpsPerSecond) !== undefined) {
                    startingRate = options.throttling.initialOpsPerSecond;
                }




                if (maxRate < startingRate) {
                    startingRate = maxRate;
                }


                if (startingRate < this._maxBatchSize) {
                    this._maxBatchSize = startingRate;
                }
            }
            this._rateLimiter = new rate_limiter_1.RateLimiter(startingRate, RATE_LIMITER_MULTIPLIER, RATE_LIMITER_MULTIPLIER_MILLIS, maxRate);
        }
    }
    
    create(documentRef, data) {
        this._verifyNotClosed();
        return this._enqueue(documentRef, 'create', bulkCommitBatch => bulkCommitBatch.create(documentRef, data));
    }
    
    delete(documentRef, precondition) {
        this._verifyNotClosed();
        return this._enqueue(documentRef, 'delete', bulkCommitBatch => bulkCommitBatch.delete(documentRef, precondition));
    }
    
    set(documentRef, data, options) {
        this._verifyNotClosed();
        return this._enqueue(documentRef, 'set', bulkCommitBatch => {
            if (options) {
                return bulkCommitBatch.set(documentRef, data, options);
            }
            else {
                return bulkCommitBatch.set(documentRef, data);
            }
        });
    }
    
    update(documentRef, dataOrField, ...preconditionOrValues) {
        this._verifyNotClosed();
        return this._enqueue(documentRef, 'update', bulkCommitBatch => bulkCommitBatch.update(documentRef, dataOrField, ...preconditionOrValues));
    }
    
    
    onWriteResult(successCallback) {
        this._successFn = successCallback;
    }
    
    
    onWriteError(shouldRetryCallback) {
        this._errorHandlerSet = true;
        this._errorFn = shouldRetryCallback;
    }
    
    flush() {
        this._verifyNotClosed();
        this._scheduleCurrentBatch( true);


        if (this._bufferedOperations.length > 0) {
            this._bufferedOperations[this._bufferedOperations.length - 1].operation.markFlushed();
        }
        return this._lastOp;
    }
    
    close() {
        if (!this._closePromise) {
            this._closePromise = this.flush();
            this.firestore._decrementBulkWritersCount();
        }
        return this._closePromise;
    }
    
    _verifyNotClosed() {
        if (this._closePromise) {
            throw new Error('BulkWriter has already been closed.');
        }
    }
    
    _scheduleCurrentBatch(flush = false) {
        if (this._bulkCommitBatch._opCount === 0)
            return;
        const pendingBatch = this._bulkCommitBatch;
        this._bulkCommitBatch = new BulkCommitBatch(this.firestore, this._maxBatchSize);

        const highestBackoffDuration = pendingBatch.pendingOps.reduce((prev, cur) => (prev.backoffDuration > cur.backoffDuration ? prev : cur)).backoffDuration;
        const backoffMsWithJitter = BulkWriter._applyJitter(highestBackoffDuration);
        const delayedExecution = new util_1.Deferred();
        if (backoffMsWithJitter > 0) {
            (0, backoff_1.delayExecution)(() => delayedExecution.resolve(), backoffMsWithJitter);
        }
        else {
            delayedExecution.resolve();
        }
        delayedExecution.promise.then(() => this._sendBatch(pendingBatch, flush));
    }
    
    async _sendBatch(batch, flush = false) {
        const tag = (0, util_1.requestTag)();


        const underRateLimit = this._rateLimiter.tryMakeRequest(batch._opCount);
        if (underRateLimit) {
            await batch.bulkCommit({ requestTag: tag });
            if (flush)
                this._scheduleCurrentBatch(flush);
        }
        else {
            const delayMs = this._rateLimiter.getNextRequestDelayMs(batch._opCount);
            (0, logger_1.logger)('BulkWriter._sendBatch', tag, `Backing off for ${delayMs} seconds`);
            (0, backoff_1.delayExecution)(() => this._sendBatch(batch, flush), delayMs);
        }
    }
    
    static _applyJitter(backoffMs) {
        if (backoffMs === 0)
            return 0;

        const jitter = exports.DEFAULT_JITTER_FACTOR * (Math.random() * 2 - 1);
        return Math.min(backoff_1.DEFAULT_BACKOFF_MAX_DELAY_MS, backoffMs + jitter * backoffMs);
    }
    
    _enqueue(ref, type, enqueueOnBatchCallback) {
        const bulkWriterOp = new BulkWriterOperation(ref, type, this._sendFn.bind(this, enqueueOnBatchCallback), this._errorFn.bind(this), this._successFn.bind(this));






        const userPromise = bulkWriterOp.promise.catch(err => {
            if (!this._errorHandlerSet) {
                throw err;
            }
            else {
                return bulkWriterOp.promise;
            }
        });


        this._lastOp = this._lastOp.then(() => (0, util_1.silencePromise)(userPromise));



        if (this._pendingOpsCount < this._maxPendingOpCount) {
            this._pendingOpsCount++;
            this._sendFn(enqueueOnBatchCallback, bulkWriterOp);
        }
        else {
            this._bufferedOperations.push(new BufferedOperation(bulkWriterOp, () => {
                this._pendingOpsCount++;
                this._sendFn(enqueueOnBatchCallback, bulkWriterOp);
            }));
        }



        return userPromise
            .then(res => {
            this._pendingOpsCount--;
            this._processBufferedOps();
            return res;
        })
            .catch(err => {
            this._pendingOpsCount--;
            this._processBufferedOps();
            throw err;
        });
    }
    
    _processBufferedOps() {
        if (this._pendingOpsCount < this._maxPendingOpCount &&
            this._bufferedOperations.length > 0) {
            const nextOp = this._bufferedOperations.shift();
            nextOp.sendFn();
        }
    }
    
    _sendFn(enqueueOnBatchCallback, op) {



        if (op.backoffDuration > 0) {
            if (this._bulkCommitBatch.pendingOps.length >= exports.RETRY_MAX_BATCH_SIZE) {
                this._scheduleCurrentBatch( false);
            }
            this._bulkCommitBatch.setMaxBatchSize(exports.RETRY_MAX_BATCH_SIZE);
        }
        if (this._bulkCommitBatch.has(op.ref)) {


            this._scheduleCurrentBatch();
        }
        enqueueOnBatchCallback(this._bulkCommitBatch);
        this._bulkCommitBatch.processLastOperation(op);
        if (this._bulkCommitBatch._opCount === this._bulkCommitBatch.maxBatchSize) {
            this._scheduleCurrentBatch();
        }
        else if (op.flushed) {


            this._scheduleCurrentBatch( true);
        }
    }
}
exports.BulkWriter = BulkWriter;

function validateBulkWriterOptions(value) {
    if ((0, validate_1.validateOptional)(value, { optional: true })) {
        return;
    }
    const argName = 'options';
    if (!(0, util_1.isObject)(value)) {
        throw new Error(`${(0, validate_1.invalidArgumentMessage)(argName, 'bulkWriter() options argument')} Input is not an object.`);
    }
    const options = value;
    if (options.throttling === undefined ||
        typeof options.throttling === 'boolean') {
        return;
    }
    if (options.throttling.initialOpsPerSecond !== undefined) {
        (0, validate_1.validateInteger)('initialOpsPerSecond', options.throttling.initialOpsPerSecond, {
            minValue: 1,
        });
    }
    if (options.throttling.maxOpsPerSecond !== undefined) {
        (0, validate_1.validateInteger)('maxOpsPerSecond', options.throttling.maxOpsPerSecond, {
            minValue: 1,
        });
        if (options.throttling.initialOpsPerSecond !== undefined &&
            options.throttling.initialOpsPerSecond >
                options.throttling.maxOpsPerSecond) {
            throw new Error(`${(0, validate_1.invalidArgumentMessage)(argName, 'bulkWriter() options argument')} "maxOpsPerSecond" cannot be less than "initialOpsPerSecond".`);
        }
    }
}

